\chapter{Detector Projects} \label{app:project}

Each collaborator must contribute to the operation of the CMS detector
before his or her name is added to the author list.
The operation of the detector is distinct from analyzing the data generated by the detector,
so all collaborators must adopt some role outside of being a physicist.

This appendix details projects I completed
in order to contribute to the operation of the CMS detector.
The first project presented is the Dynamo Consistency project.
It is a plugin for the dynamic data management system Dynamo \cite{iiyama2020dynamo}
that compares the inventory of files Dynamo expects at a site
with the files that are actually at a site.
The other project described is known as Workflow Web Tools.
This is a dynamic web server that displays errors reported
by the CMS computing infrastructure to operators,
and allows those operators to perform corrective actions through the web page.
Workflow Web Tools also tracks operator actions for future use
in training various machine learning models.
Both projects are published as software packages written in Python
\cite{van1995python, 10.5555/1593511}
and are available through the Python Package Index (PyPI) as
\texttt{dynamo-consistency} and \texttt{workflowwebtools}, respectively.


\section{Dynamo Consistency}

Dynamo Consistency is a plugin for Dynamo Dynamic Data Management System that checks
consistency between Dynamo’s inventory and files actually located at managed sites.
Even though Dynamo controls and tracks the history of file transfers between computing sites,
a separate check is needed to ensure files are
not lost or accumulated due to user or system errors.
For example, sites that can no longer access some files after a power outage
can cause problems for many related activities.
File transfers requested from a inconsistent site to another site will fail
when files are missing.
Sites will be also be chosen incorrectly for production jobs
that assume the presence of a local file.
Last disk copies may also be missing, causing a significant delay when a user requests data.
Another type of inconsistency arises when files thought to be deleted are still on disk.
This leads to wasted disk space for files that are not accessed, except by accident.
Dynamo Consistency regularly checks consistency by listing each remote site and
comparing the listed contents to Dynamo’s inventory database.
The results are reported back to Dynamo, which can then take corrective measures.

A single executable \texttt{dynamo-consistency} is provided to run the consistency check.
This executable can be used directly in Dynamo’s scheduling system.
Most of the behaviour is controlled via a single JSON configuration file,
with options for site selection, passed via command line arguments.
Differing command line arguments allows Dynamo to run separate schedules
for differing site architectures.

Because Dynamo runs in a heterogeneous computing environment,
different sites need to be listed remotely using different methods.
Currently implemented are listings using XRootD Python bindings,
the \texttt{gfal-ls} CLI \cite{laure2006programming}, and a \texttt{xrdfs} subshell.
These listers are easily extensible in Python,
allowing for new site architectures to be added to Dynamo Consistency as well.

The default executable performs the check as expected,
listing files that are not tracked by Dynamo as orphans
and listing files that are not found at sites as missing.
A few configurable filters can be added to modify these lists.
Dynamo Consistency avoids listing orphan files that have a modification time that is recent.
Paths to avoid deleting can also be set.
Deletion and transfer requests that are queued are also used to filter the final report
to avoid redundant actions from Dynamo.

In addition to tracking the consistency between Dynamo’s inventory and physical site storage,
Dynamo Consistency can report all remote files older than a certain age
in general directories.
These files can also be filtered with path patterns, just as the regular consistency check.
The time-based only reporting allows for cleaning of directories that Dynamo does not track.
This is a setting recommended for large file systems
that are written to with a high frequency.

Summaries of check results, as well as the statuses of running checks,
are displayed in a web page.
The page consists of a table that includes links to logs and
lists of orphan and missing files.
Cells are color coded to allow operators to quickly identify problematic sites.
Historic summary data for each site is also accessible through this page.

If the available configuration options and listers are not enough,
advanced users can also directly use the Python API to run a custom consistency check.
For more details on the Dynamo Consistency package,
see \cite{dynamo_consistency}.

\subsection{Installation}

Dynamo Consistency requires the XRootD \cite{dorigo2005xrootd}
Python module to be installed separately.
In addition, it uses the Dynamo Dynamic Data Management package to get inventory listings
and to report results of the consistency check.
Any other needed packages are installed with Dynamo Consistency during installation.

The simplest way to install is through pip:

\begin{verbatim}
pip install dynamo-consistency
\end{verbatim}

The source code is maintained on GitHub \cite{dynamo_consistency_src}.
Other typical \texttt{setuptools} methods are supported by
the repository’s \texttt{setup.py}.

\subsection{Inventory Listing}

Two listings must be done to compare.
One is the Inventory Listing,
and the other is the Remote Listing.
This section describes the inventory listing, and the next describes remote listing.

The inventory is queried before the site is listed remotely due to possible race conditions.
It is not uncommon for a site listing to take multiple days.
In the meanwhile, two things can change in the inventory.
A file can be deleted from a site or it can be added to a site.
An added file is ignored by setting {\bf IgnoreAge}
in the configuration to a large enough value.
Files that are deleted during the remote listing
are filtered out by checking recent deletion requests after the remote listing.

There are currently multiple ways to get the site contents from Dynamo.
One is to access the MySQL database use for Dynamo storage directly.
This will work as long as the schema does not change.
A more reliable way to keep up with major changes in Dyanmo
is to use the Dynamo inventory object.
This method is less optimized when working with the MySQL storage plugin,
but will work for different schema and any different storage types
that are added in the future.

The type of inventory lister is selected via command line options,
or by setting \texttt{dynamo\_consistency.opt.V1} to \texttt{True} or \texttt{False}
before importing any modules that rely on the backend.
By implementing the three modules \texttt{inventory}, \texttt{registry},
and \texttt{siteinfo}, described in the full documentation \cite{dynamo-consistency},
any other method of communicating with an inventory can be added.

After selecting the backend,
the inventory can be listed transparently using the following method:

\begin{verbatim}
from dynamo_consistency import inventorylister
listing = inventorylister.listing(sitename)
\end{verbatim}

Here, \texttt{listing} is a \texttt{dynamo\_consistency.datatypes.DirectoryInfo} object
that is the root node of the full directory tree.
Each node of \texttt{DirectoryInfo} contains meta data about a directory,
such as its modification timestamp and name.
It also holds a list of sub-directories, in the form of \texttt{DirectoryInfo} objects,
and a list of files.
The files are represented as dictionaries containing the name, size,
and modification time of the file.
Each file and \texttt{DirectoryInfo} also stores a hash of the meta data.
The \texttt{DirectoryInfo} hash includes information from the object’s
files and sub-directories too.
This is to speed up the file tree comparison, shown in Figure~\ref{fig:comparison}

\begin{figure}[htp]\centering\capstart\begin{tikzpicture}
[node distance=0.3cm, every edge/.style={arrow}]
\node (start) [goodstep] at (0,0) {Init empty \\ file list};
\node (realstart) [goodstep, below=of start] {Start \\ compare};
\node (treecheck) [goodstep, right=of start] {Other \\ tree?};
\node (tree) [goodstep, above=0.5cm of treecheck] {Hash \\ match?};
\draw [->, thick] (treecheck) -- node [font=\scriptsize, left] {Yes} (tree);
\node (nohash) [goodstep, below right=0.2cm and 0.6cm of tree] {For sub- \\ directory};
\draw [->, thick] (tree) -- node [font=\scriptsize, above] {No} (nohash);
\node (subdir) [goodstep, below=0.5cm of nohash] {if comparable \\
  \textcolor{gray}{get other and} \\
  add files \\ (start again)};
\node (files) [goodstep, right=of nohash] {for file};
\node (checkfile) [goodstep, below=0.5cm of files] {if comparable \\
  \textcolor{gray}{and no matching} \\
  \textcolor{gray}{hash in other,} \\ filter and append};
\draw [->, thick] (treecheck) -- node [font=\scriptsize, below] {No} (nohash);
\draw [->, dashed] (subdir) -- (realstart);
\draw [->, thick] (nohash) -- node [font=\scriptsize, right] {Loop} (subdir);
\draw [->, thick] (files) -- node [font=\scriptsize, right] {Loop} (checkfile);
\node (final) [goodstep, above=of files] {return full \\ files list};
\node (match) [goodstep, right=0.6cm of tree] {Return empty \\ file list};
\draw [->, thick] (tree) -- node [font=\scriptsize, above] {Yes} (match);
\path
(realstart) edge (start)
(start) edge (treecheck)
(nohash) edge (files)
(files) edge (final);

\end{tikzpicture}\caption{Comparison algorithm}\label{fig:comparison}\end{figure}

\subsection{Remote Listing}

The remote listing is equally flexible in terms of having
multiple implementations used for the listing.
The factory function \texttt{dynamo\_consistency.backend.get\_listers()}
reads the configuration file to determine the type of lister for each site.
There are currently three different classes implemented,
and more can be added by extending the \texttt{dynamo\_consistency.backend.listers.Lister}
class and implementing its \texttt{ls\_directory} method.
The three current listers are the following:
\begin{itemize}
\item \texttt{dynamo\_consistency.backend.listers.XRootDLister} -
  This listing object uses the \texttt{XRootD} Python module
  to connect to and query each site.
\item \texttt{dynamo\_consistency.backend.listers.GFalLister} -
  This listing object uses the \texttt{gfal-ls} command line tool to list remote sites.
\item \texttt{dynamo\_consistency.backend.listers.XRootDLister} -
  This listing object opens a subshell using the \texttt{xrdfs}
  command line tool and queries the remote site.
\end{itemize}

Once the type of lister is set in the configuration
the contents of the remote site can be gathered with a simple interface:

\begin{verbatim}
from dynamo_consistency import remotelister
listing = remotelister.listing(sitename)
\end{verbatim}

This takes much longer than the Inventory Listing,
since every directory of the site needs to be queried over the network.
A software layer between the listing class and
the final output creates multiple connections and works on two queues with multiple threads.
There is the input queue, which is a list of directories that still need to be listed, and
an output queue which holds the result of each directory listed so far.
The workflow of the listing is shown in Figure~\ref{fig:listing}.
\begin{figure}[htp]\centering\capstart\begin{tikzpicture}
[node distance=0.5cm, every edge/.style={arrow}]
\node (start) [goodstep] at (0, 0) {List directory};
\node (good) [goodstep, right=of start] {Was the listing successful?};
\node (yes) [below=of good] {Yes};
\node (outqueue) [async, below=of yes] {Output name of \\ this directory \\
  and lists of \\ subdirectories and files};
\node (inqueue) [async, left=of yes] {For each in \\ queue};
\node (master) [goodstep, right=of outqueue] {Get this from master \\
  add directories \\ add files};
\node (try) [async, above=of good] {Try again};
\draw [->, thick] (good) -- node [left] {No} (try);
\node (storestart) [goodstep, left=of outqueue] {Add starting directory \\
  to listing queue};
\path
(start) edge (good)
(inqueue) edge [bend left] node [left] {} (start)
(outqueue) edge (master)
(good) edge (yes)
(yes) edge (inqueue) edge (outqueue)
(try) edge [bend right] node [above] {} (start)
(storestart) edge (inqueue);

\end{tikzpicture}\caption{Listing algorithm with retries}\label{fig:listing}\end{figure}

\subsection{Executables}

Other tools are available as part of \texttt{dynamo-consistency}
in order to simplify operating the system.
Many of these come as separate executables.
A list of some of the executables installed with the package is given below.

\subsubsection{dynamo-consistency}

This program runs the Site Consistency Check for
Dynamo Dynamic Data Management System.
{\small
\begin{verbatim}
Usage: dynamo-consistency [options]

Options:
  --version             show program's version number and exit
  -h, --help            show this help message and exit
  --config=FILE         Sets the location of the configuration file to read.

  Selection Options:
    --site=PATTERN      Sets the pattern used to select a site to run on next.
    --lock=NAME         Sets the lock name that should be used for this run.
    --date-string=YYYYMMDD
                        Set the datestring to pull for RAL-Reader listers

  Logging Options:
    --update-summary    Forces the update of the summary table, even if
                        loading trees
    --email             Send an email on uncaught exception.
    --info              Displays logs down to info level.
    --debug             Displays logs down to debug level.

  Behavior Options:
    These options will change the backend loaded and actions taken

    --no-orphan         Do not delete any orphan files.
    --cms               Run actions specific to CMS collaboration data.
    --no-sam            Disables the SAM readiness check.
    --more-logs         Clean any "AdditionalLogDeletions" directories.
    --no-inventory      Do not connect the inventory. Used to test unmerged
    --unmerged          Run actions on "/store/unmerged".
    --v1                Connect to Dynamo database directly
    --v1-reporting      Connect to Dynamo database directly for registry only.
    --cnf=FILE          Point to a non-default location of a ``my.cnf`` file.
    --test              Run with a test instance of backend module.
\end{verbatim}
}

\subsubsection{set-status}

This script changes the status of a site on the summary webpage.
It can be used to unlock from a dead process, disable sites from running,
and change whether or not to act on the site.
This script can take a \texttt{--config <FILE>} parameter to point
to a configuration file, a la \texttt{dynamo-consistency}.
For the last two arguments, \texttt{SITE} will match
the name of the site to change.
\texttt{ACTION} can be one of the entries in Table~\ref{tab:status-actions}
%
\begin{table}
  \caption[\texttt{dynamo-consistency} site statuses]{
    Valid statuses for sites as tracked by \texttt{dynamo-consistency}
    are described below.
  }
  {\renewcommand{\arraystretch}{1.5}
  \begin{tabularx}{\textwidth}{|c|X|}
    \hline
    Action & Description \\
    \hline
    \hline
    \texttt{ready} &
    This sets the site status back to idle.
    This means the site is ready to run.
    Should be used on a site that's disabled. \\
    \hline
    \texttt{halt} &
    This stops a currently running or locked site.
    This site is still eligible to run. \\
    \hline
    \texttt{disable} &
    Can be applied to a site that is either running or ready.
    It halts the site and also prevents it from running until set to \texttt{ready} again. \\
    \hline
    \texttt{act} &
    Marks a site as one to report results to the registry. \\
    \hline
    \texttt{dry} &
    Opposite of \texttt{act},
    this action prevents this site from making entries into the registry in future runs. \\
    \hline
  \end{tabularx}}
  \label{tab:status-actions}
\end{table}
{\small
\begin{verbatim}
Usage: set-status [options] SITE ACTION

Options:
  --version      show program's version number and exit
  -h, --help     show this help message and exit
  --config=FILE  Sets the location of the configuration file to read.

  Logging Options:
    --info       Displays logs down to info level.
    --debug      Displays logs down to debug level.
\end{verbatim}
}

\subsubsection{consistency-dump-tree}

Dumps the \texttt{dynamo\_consistency.datatypes.DirectoryInfo}
tree into the cache directory.
By default, it dumps the tree that would be read from the inventory.

If the \texttt{[NAME]} argument is not given, defaults to \texttt{inventory.pkl}
or \texttt{remote.pkl} when using the \texttt{-{-}remote} option.
{\small
\begin{verbatim}
Usage: consistency-dump-tree [options] [NAME]

Options:
  --version             show program's version number and exit
  -h, --help            show this help message and exit
  --config=FILE         Sets the location of the configuration file to read.

  Selection Options:
    --site=PATTERN      Sets the pattern used to select a site to run on next.
    --remote            Dump the remote site listing instead of the inventory
    --date-string=YYYYMMDD
                        Set the datestring to pull for RAL-Reader listers

  Logging Options:
    --info              Displays logs down to info level.
    --debug             Displays logs down to debug level.

  Behavior Options:
    These options will change the backend loaded and actions taken

    --unmerged          Run actions on "/store/unmerged".
    --v1                Connect to Dynamo database directly
    --test              Run with a test instance of backend module.
\end{verbatim}
}

\subsubsection{check-phedex}

This program is only useful for double-checking CMS sites.
This program checks a site's orphan files against PhEDEx.
If any of the datasets are supposed to be at the site,
this gives a non-zero exit code.

{\small
\begin{verbatim}
Usage: check-phedex [options] SITE

Options:
  --version      show program's version number and exit
  -h, --help     show this help message and exit
  --config=FILE  Sets the location of the configuration file to read.

  Logging Options:
    --info       Displays logs down to info level.
    --debug      Displays logs down to debug level.
\end{verbatim}
}

\subsection{Configuration}

The configuration file for \texttt{dynamo-consistency}
is a JSON or YAML file with the following keys.
\begin{itemize}
\item {\bf AccessMethod} -
  A dictionary of access methods for sites.
  Sites default to XRootD, but setting a value of \texttt{SRM}
  causes the site to be listed by \texttt{gfal-ls} commands.
\item {\bf AdditionalLogDeletions} -
  A dictionary that lists which directories have logs to be cleaned for different sites.
  These log directories are treated the same as log directories in \texttt{/store/unmerged}.
  This means they use the {\bf UnmergedLogsAge} parameter to determine cleaning policy.
\item {\bf DirectoryList} -
  A list of directories inside of {\bf RootPath} to check consistency.
\item {\bf DeleteOrphans} -
  By default, is true.
  If set to false, orphan files will all be filtered out so that none are deleted.
\item {\bf FreeMem} -
  The amount of free memory that is required for a check to run.
  The memory is given in GBs.
\item {\bf GFALThreads} -
  The number of threads used by the GFAL listers
\item {\bf GlobalRedirectors} -
  The redirectors to start all locate calls from,
  unless looking for a site that is listed in the {\bf Redirectors} configuration.
\item {\bf IgnoreAge} -
  Ignore any files or directories with an age less than this, in days.
\item {\bf IgnoreDirectories} -
  The check ignores any paths that contain any of the strings in this list.
\item {\bf InventoryAge} -
  The age, in days, of how old the information from the inventory can be
\item {\bf ListAge} -
  The age, in days, of how old the list of files directly from the site can be
\item {\bf ListDeletable} -
  Configuration for unmerged cleaning “listdeletable” module.
  Details on some of the configuration parameters are documented online \cite{unmerged_opts}.
\item {\bf MaxMissing} - If more files than this number are missing,
then there will be no automatic entry into the register.
\item {\bf MaxOrphan} - If more than files than this number are orphan files at a site,
then there will be no automatic entry into the register.
\item {\bf NumThreads} - The number of threads used by the XRootD listers
\item {\bf PathPrefix} -
  A dictionary of prefixes to place before {\bf RootPath} in the XRootD call.
  This allows for different paths for different sites.
  If the prefix is not set for a site, and it fails to list {\bf RootPath},
  it falls back to a default \texttt{/cms} before giving up.
\item {\bf RedirectorAge} -
  The age, in days, of how old the information on doors from redirectors can be.
  If this value is set to zero, the redirector information is never refreshed.
\item {\bf Redirectors} - A dictionary with keys of sites with hard-coded redirector locations.
  If a site is not listed in this way, the redirector is found by matching domains from
  \texttt{CMSToolBox.siteinfo.get\_domain()}
  to redirectors found in a generic \texttt{xrdfs locate} call.
\item {\bf Retries} - Number of retries after timeouts to attempt
\item {\bf RootPath} - The directory where all of the listed subdirectories will be under.
  For CMS sites, this will be \texttt{"/store"}
\item {\bf SaveCache} -
  If set and evaluates to True, copies old cached directory trees instead of overwriting
\item {\bf Timeout} -
  This gives the amount of time, in seconds, that you want the listing to try to run
  on a single directory before it times out.
\item {\bf Unmerged} - A list of sites to handle cleaning of \texttt{/store/unmerged} on.
  If the list is empty, all the sites are managed centrally
\item {\bf UnmergedLogsAge} - The minimum age of the unmerged logs to be deleted, in days
\item {\bf UseLoadBalancer} - A list of sites where the main redirector of the site is used
\item {\bf UseTransferQueue} - If true, put missing files into tranfer queue table
  when using \texttt{-{-}v1} for reporting. Defaults to true value.
\item {\bf VarLocation} - The location for the varying directory.
  Inside this directory will be:
  \begin{itemize}
  \item Logs
  \item Redirector lists
  \item Cached trees
  \item Lock files
  \end{itemize}
\item {\bf WebDir} - The directory where text files and the sqlite3 database are stored
\end{itemize}

Configuration parameters can also be quickly overwritten for a given run by
setting an environment variable of the same name.

\subsection{Comparison Script}

The full set of operations in a typical run of the \texttt{dynamo-consistency}
is enumerated below.
\begin{enumerate}
\item Points \texttt{config.py} to the local \texttt{consistency\_config.json} file
\item Notes the time, and if it’s daylight savings time for entry into the summary database
\item Reads the list of previous missing files,
  since it requires a file to be missing on multiple
  runs before registering it to be copied
\item It gathers the inventory tree by calling \\
  \texttt{dynamo\_consistency.getinventorycontents.get\_db\_listing()}.
\item Creates a list of datasets to not report missing files in.
  This list consists of deletion requests fetched from PhEDEx by \\
  \texttt{dynamo\_consistency.checkphedex.set\_of\_deletions()}
\item It creates a list of datasets to not report orphans in.
  This list consists of the following.
  \begin{itemize}
  \item Datasets that have any files on the site, as listed by the dynamo MySQL database
  \item Deletion requests fetched from PhEDEx (same list as datasets to skip in missing)
  \item Any datasets that have the status flag set to \texttt{`IGNORED'}
    in the dynamo database
  \item Merging datasets that are protected by Unified
  \end{itemize}
\item It gathers the site tree by calling \\
  \texttt{dynamo\_consistency.getsitecontents.get\_site\_tree()}.
  The list of orphans is used during the running to filter out empty directories that are
  reported to the registry during the run.
\item Does the comparison between the two trees made,
  using the configuration options concerning file age.
\item If the number of missing files is less than {\bf MaxMissing},
  the number of orphans is less than {\bf MaxOrphan},
  and the site is under the webpage’s “Debugged sites” tab,
  connects to a dynamo registry to report the following errors:
  \begin{itemize}
  \item Every orphan file and every empty directory that is not too new
    nor should contain missing files is entered in the deletion queue.
  \item For each missing file, every possible source site as listed by the dynamo database,
    (not counting the site where missing), is entered in the transfer queue.
    Creates a text file full of files that only exist elsewhere on tape.
  \end{itemize}
\item Creates a text file that contains the missing blocks and groups.
\item \texttt{.txt} file lists and details of orphan and missing files are moved
  to the web space
\item If the site is listed in the configuration under the {\bf Unmerged} list,
  the unmerged cleaner is run over the site:
  \begin{itemize}
  \item \texttt{dynamo\_consistency.getsitecontents.get\_site\_tree()} is run again,
    this time only over \texttt{/store/unmerged}
  \item Empty directories that are not too new nor protected by Unified
    are entered into the deletion queue
  \item The list of files is passed through the unmerged cleaner
  \item The list of files to delete from unmerged cleaner
    are entered in the deletion queue
  \end{itemize}
\item The summary database is updated to show the last update on the website
\end{enumerate}

\section{Workflow Web Tools}


\subsection{Motivation}


\subsection{Function}


\subsection{Models for Machine Learning}


\subsection{Automatic Error Handling}

