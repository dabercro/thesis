\chapter{Analysis Results} \label{ch:results}

\section{Run 2 Data Collection}

The CMS detector collected proton-proton collision data at $\sqrt{s} = \SI{13}{TeV}$
over three years during Run 2 of the LHC.
In 2016, CMS collected \SI{37.80}{fb^{-1}} of data \cite{CMS-PAS-LUM-17-001}.
In 2017, \SI{44.98}{fb^{-1}} of data was collected \cite{CMS-PAS-LUM-17-004}.
In 2018, CMS collected \SI{63.67}{fb^{-1}} of collision data \cite{CMS-PAS-LUM-18-002}.


\section{Corrections and Uncertainties}

Despite efforts to simulate LHC collisions as accurately as possible,
a number of differences in the distributions predicted by MC and present in data arise.
This is a result of not being able to predict the beam conditions exactly
and not being able to predict the calibration accurately.
This is made more difficult since the detector degrades in its high radiation environment.

Corrections are made to the simulation by re-weighting based on the pileup
and by scaling the predicted energies based on particle type.
Most of the corrections are derived by dedicated groups that provide
the entire CMS collaboration with proper calibrations.
This analysis does depend in particular on predictions of $b$-jet energies,
which are not corrected centrally.
Therefore this section includes a description of how that correction is derived.

\subsection{Muons}

To remove fake muons from events, muons are selected in three ways.
Muon identification cuts are applied, isolation cuts are applied,
and certain triggers are required.
These three things each behave differently in MC and data.
For each of these, a separate efficiency is derived in MC and data.
These are measured via the Tag and Probe method,
selecting muons that reconstruct the $Z$ boson resonance.
A scale factor is then applied to MC to match the data efficiency.

Each of the efficiency measurements and scale factors are binned
in muon $p_T$ and $\eta$.
The $p_T$ bins are $[20, 25, 30, 40, 50, 60, \infty)$ in GeV.
Bins in $|\eta|$ are delimited at $[0, 0.9, 1.2, 2.1, 2.4]$.

\subsection{Electrons}

\subsection{Jets and MET}

\subsection{$b$-Jet Energy Correction}

Even when distributions of individual variables agree between MC and data,
correlations are often different.
These correlations are also important in the evaluation of a DNN.
The DNN used to estimate the energy of $b$-jets therefore has differing performance
in MC and data.
In particular, it is better at estimating the true energy of a $b$-jet in MC.
The energies evaluated in MC must be smeared in order to accurately simulate
the resolution of jets in data after they have been modified by the DNN regression.

One way to measure jet energy resolution is to consider an event
where a jet is recoiling off of a Z boson that decays into leptons.
In principle, the $Z$ boson's transverse momentum is balanced with the
jet's transverse momentum.
Measurements of lepton energies in the CMS detector is relatively precise,
so the ratio of the reconstructed jet's
$p_T$ to the $Z$ boson's $p_T$ allows measurement of the jet energy resolution.
Ideally, this measurement would be done with an collision resulting in one $Z$ boson decay,
and one jet.
However, this is an infrequent occurrence.
Instead, events with two jets are selected, with one jet having relatively low $p_T$.
A fit is performed to estimate resolution characteristics
where the second jet would have $p_T = \SI{0}{GeV}$.

These events are selected using the following requirements:

\begin{itemize}
\item Exactly two muons or two electrons must pass the selection criteria for the
  di-leptons channels described in Section~\ref{sec:resolved-2}.
\item The two selected leptons must be oppositely charged.
\item The di-lepton kinematics must satisfy \\ $p_{T,\ell\ell} > \SI{100}{GeV}$ and
  $\SI{71}{GeV} < m_{\ell\ell} < \SI{111}{GeV}$.
\item Exactly two jets must pass the pre-selection described in Section~\ref{sec:resolved-2}.
\item The leading jet must also satisfy $\Delta\phi(j, \ell\ell) > 2.8$
\item The ratio between the sub-leading jet $p_T$ and
  the di-lepton $p_T$ must be less than 0.3.
\item The leading jet must pass the tight working point for the $b$-tagger,
  as defined for each year in Table~\ref{tab:deepcsv}.
\end{itemize}

The selected events are divided into four bins of $\alpha = p_{T,j2}/p_{T, \ell\ell}$
with bounds $(0, 0.155, 0.185, 0.23, 0.3)$.
The jet response ($p_{T, j1}/p_{T, \ell\ell + j2}$) is plotted in each bin, with uncertainties from
renormalization and refactorization scale weights and parton shower weights.
These histograms of jet response are shown in Fig.~\ref{fig:jetsmear-responses}.
From each plot, the mean ($\mu$) and the standard deviation ($\sigma$) are extracted.
$\sigma/\mu$ is fit as a function of $\alpha$.

\begin{figure}
  \centering
  \includegraphics[width=0.23\linewidth]{figures/201019_2016/smearplot_1_jet1_adjusted_response.pdf}
  \includegraphics[width=0.23\linewidth]{figures/201019_2016/smearplot_2_jet1_adjusted_response.pdf}
  \includegraphics[width=0.23\linewidth]{figures/201019_2016/smearplot_3_jet1_adjusted_response.pdf}
  \includegraphics[width=0.23\linewidth]{figures/201019_2016/smearplot_4_jet1_adjusted_response.pdf} \\
  \includegraphics[width=0.23\linewidth]{figures/201019_2017/smearplot_1_jet1_adjusted_response.pdf}
  \includegraphics[width=0.23\linewidth]{figures/201019_2017/smearplot_2_jet1_adjusted_response.pdf}
  \includegraphics[width=0.23\linewidth]{figures/201019_2017/smearplot_3_jet1_adjusted_response.pdf}
  \includegraphics[width=0.23\linewidth]{figures/201019_2017/smearplot_4_jet1_adjusted_response.pdf} \\
  \includegraphics[width=0.23\linewidth]{figures/201019_2018/smearplot_1_jet1_adjusted_response.pdf}
  \includegraphics[width=0.23\linewidth]{figures/201019_2018/smearplot_2_jet1_adjusted_response.pdf}
  \includegraphics[width=0.23\linewidth]{figures/201019_2018/smearplot_3_jet1_adjusted_response.pdf}
  \includegraphics[width=0.23\linewidth]{figures/201019_2018/smearplot_4_jet1_adjusted_response.pdf} \\
  \caption[Reponse to evaluate jet smearing]{
    The histograms of reponse for each event are shown above.
    The top row shows 2016, the middle shows 2017, and the bottom row shows 2018 histograms.
  }
  \label{fig:jetsmear-responses}
\end{figure}

\begin{gather}
  f(\alpha) = (m \times \alpha) \oplus b \times (1 + c_k \times \alpha)
\end{gather}

$c_k$ is fixed by a linear fit to the MC's intrinsic jet resolution ($p_{T, reco}/p_{T, gen}$) over $\alpha$ as $c_k = m_0/q_0$.
The fit results are shown in Fig.~\ref{fig:jetsmear-fits}.
Smearing is done by scaling difference between $p_{T,reco}$ and $p_{T,gen}$ by $b_{data}/b_{MC}$.
This causes the post-smearing fits to agree at $\alpha = 0$.
Uncertainties are extracted from the fit uncertainties of $b$ for data and MC.
The resulting smearings are in Table~\ref{tab:jetsmear-res}.

\begin{figure}
  \centering
  \includegraphics[width=0.3\linewidth]{figures/201015_smear_201015_2016_tight_divmean/resolution_jet1_adjusted_response_smear_0.pdf}
  \includegraphics[width=0.3\linewidth]{figures/201012_smear_201012_2017_tight_divmean/resolution_jet1_adjusted_response_smear_0.pdf}
  \includegraphics[width=0.3\linewidth]{figures/201004_smear_201002_2018_divmean/resolution_jet1_adjusted_response_smear_0.pdf}
  \caption[Resolution fits for jet smearing]{
    The fits to Data, MC, and intrinsic resolutions are shown.
    From left to right are the fits for 2016, 2017, and 2018.
  }
  \label{fig:jetsmear-fits}
\end{figure}

\begin{table}
  \centering
  \caption{The extracted smearing needed for each year of data as a percent of the jet's $p_T$.}
  \begin{tabular}{c|c|c}
    \hline
    Year & Scaling & Smearing \\
    \hline
    2016 & $0.998 \pm 0.019$ & $0.017 \pm 0.060$ \\
    2017 & $1.020 \pm 0.023$ & $0.088 \pm 0.071$ \\
    2018 & $0.985 \pm 0.019$ & $0.080 \pm 0.073$ \\
    \hline
  \end{tabular}
  \label{tab:jetsmear-res}
\end{table}

\section{Theoretical Uncertainties}



\section{Multivariate Discriminator}

In each STXS bin, a mutlivariate discriminator is plotted which separates
the signal events from background events.
A Deep Neural Network (DNN) is trained for the resolved selection,
and a Boosted Decision Tree (BDT) is trained for the boosted selection.
Using fewer discriminating variables in the boosted events
leads to this difference in architecture.

\subsection{Resolved DNN}

The DNN classifier for distinguishing background and signal events is prepared using
Keras with a Tensorflow backend using an Adam optimizer.
It has five hidden layers.
The number of nodes in each layer, from input to output, is 512, 256, 128, 64, 64, and 64.
The final layer is a softmax layer with the target of predicting the probability
of each event belonging to a particular class.

Each channel of 0-, 1-, and 2-leptons is trained separately,
and has slightly different input variables.
The list of input variables is given in Table~\ref{tab:dnn-inputs}.
All variables that are affected by the kinematic fit in the 2-lepton region
use the values calculated by the fit.

\begin{table}
  \caption[Resolved DNN inputs]{
    The list of input variables used for each DNN training is shown.
  }
  \centering
  \begin{tabularx}{\textwidth}{|l|X|c|c|c|}
    \hline
    Variable & Explanation & 0-lepton & 1-lepton & 2-lepton \\
    \hline\hline
    $m_{jj}$ & Di-jet mass & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
    $p_{T,jj}$ & Di-jet transverse momentum & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
    MET & Missing transverse energy & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
    \hline
    $m_{T,V}$ & Vector boson transverse mass & & $\checkmark$ & \\
    $p_{T,V}$ & Vector boson $p_T$ & & $\checkmark$ & $\checkmark$ \\
    $p_{T,jj}/p_{T,V}$ & Redundant ratio & & $\checkmark$ & $\checkmark$ \\
    \hline
    $\Delta\phi(V, jj)$ & Azimuthal angle between vector boson and di-jet & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
    $b$-tag$_\mathrm{max}$ WP & 1, 2, or 3 if higher $b$-tag discriminate meets the tight, medium, or loose working point respectively & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
    $b$-tag$_\mathrm{min}$ WP & 1, 2, or 3 if lower $b$-tag discriminate meets the tight, medium, or loose working point respectively & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
    \hline
    $\Delta\eta(jj)$ & $\eta$ difference between jets & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
    $\Delta\phi(jj)$ & Azimuthal angle between jets & $\checkmark$ & $\checkmark$ & \\
    $p_{T, \mathrm{lead}}$ & Leading jet $p_T$ & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
    \hline
    $p_{T, \mathrm{trail}}$ & Trailing jet $p_T$ & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
    SA5 & Number of soft jets, $p_T > \SI{5}{GeV}$ & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
    N_{aj} & Number of additional jets & $\checkmark$ & $\checkmark$ & \\
    \hline
    $b$-tag$_\mathrm{add}$ & Maximum $b$-tag of additional jets & $\checkmark$ & & \\
    $p_{T,\mathrm{add}}$ & Maximum $p_T$ of additional jets & $\checkmark$ & & \\
    $\Delta\phi(\mathrm{add, MET})$ & Azimuthal angle between additional jet and MET & $\checkmark$ & & \\
    \hline
    $\Delta\phi(\ell, \mathrm{MET})$ & Azimuthal angle between lepton and MET & & $\checkmark$ & \\
    $m_t$ & Reconstruction top mass & & $\checkmark$ & \\
    $m_V$ & Vector boson mass & & & $\checkmark$ \\
    \hline
    $\Delta R(V, jj)$ & Separation between vector boson and di-jet & & & $\checkmark$ \\
    $\Delta R_{jj}$ & Separation between jets & & & $\checkmark$ \\
    \hline
  \end{tabularx}
  \label{tab:dnn-inputs}
\end{table}

\subsection{Boosted BDT}

The BDT used to classify signal and background events in the boosted region
was trained using ROOT.
The model uses 100 trees with 20 cuts and a minimum node size of 0.05.
The QCD multijet backgrounds were not used in the training since the sample's large weights
of individual events affected the training.

The list of input variables for the BDT is the following:
\begin{itemize}
\item Soft-drop mass of the recontructed fat jet
\item Transverse momentum of the fat jet
\item Transverse momentum of the recontructed vector boson
\item Number of soft-track jets with $p_T > \SI{5}{GeV}$
\item Double $b$-tagger output node for boosted jets
\end{itemize}
All of these variables were all used in the 0-, 1-, and 2-lepton regions,
even though the regions were trained separately.

\section{Combination Fit Method}

\section{Results}
