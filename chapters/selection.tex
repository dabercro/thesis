\chapter{Event Selection} \label{ch:selection}

This chapter gives the specific selection requirements on each physics object
that allows us to count particle candidates and to reject or otherwise classify events,
based on the decription of physics processes described thus far.
First, objects are defined in terms of variables and particle candidates provided by the
detector reconstruction algorithms.
Then selection requirements based on these objects used to reject events entirely
from the analysis are given.
After that, selection requirements used to classify events
into different decay channels of the vector boson are specified.
There are also selection requirements that allow events to be treated separately
when the Higgs decay products can be resolved as separate jets
and where they are merged into a single massive jet.

\section{Object Definitions}

Detector responses are linked to possible physical particles.
Most of the particle ID techniques described so far can give
false positives for individual particle candidates
or provide composite physics objects that are in reality composed of background particles.
What follows are tighter selections used in order to reduce these backgrounds.
Once objects are more strictly defined,
they can be used for more reliable event classification.

Each type of object generally has a method of pre-selection
and additional cuts for a selection.
The distinction is particularly useful for categorizing events.
Each category is designed to be enriched with a particular physics process.
Each physics process would result in certain final states
with specific multiplicities for some particles.
For objects, passing a pre-selection often means that the object is defined
well enough to veto events for inclusion in categories that
would not include the corresponding particle.
Additional selection requirements are added for objects to classify
as a particular particle candidate in order to reduce false positives
of events that are included in a given category.

\subsection{Variable Definitions}

Many of the object definitions use variables that have not been defined yet.
They can be understood in terms of the reconstruction
described in Section~\ref{sec:event-reco}.

Lepton isolation is quantified using the following formula.
\begin{gather}
  I = \frac{1}{p_T^\ell} \left(\sum p_T^\mathrm{charged} +
      \max\left[0, \sum p_T^\mathrm{neutral} +
               \sum p_T^\mathrm{\gamma} - p_T^\mathrm{PU}
               \right]\right) \label{eq:isolation}
\end{gather}
The sums are over charged hadrons originating from the primary vertex
and all neutral hadrons and photons within a distance of $\Delta R < 0.4$
from the lepton if it is a muon, or $\Delta R < 0.3$ from an electron.
$\Delta R$ is a distance used in the $(\eta, \phi)$ plane.
\begin{gather}
  \Delta R = \sqrt{\Delta\eta^2 + \Delta\phi^2}
\end{gather}
The term $p_T^\mathrm{PU}$ is defined as the following for muons.
\begin{gather}
  p_T^\mathrm{PU} = 0.5 \times \sum_i p_T^{\mathrm{PU},i}
\end{gather}
$i$ refers to charged hadrons that do not originate from the primary vertex.
Electrons use the following definition.
\begin{gather}
  p_T^\mathrm{PU} = \rho \times A_\mathrm{eff}
\end{gather}
$A_\mathrm{eff}$ is the area of the isolation cone,
and $\rho$ is the median of the $p_T$ density of neutral particles in that area.

Particles can also be defined as coming from the primary vertex of an event or from pileup.
Vertices are defined through deterministic annealing \cite{726788},
using the closest approach of tracks to the beamline \cite{Collaboration_2014}.
The primary vertex is the vertex with
the greatest sum of $E_T$ of the charged particles originating from it.
After identification of the primary vertex,
charged particles are classified as originating from the primary vertex or as pileup
using their extrapolated track's distance in the transverse plane, $d_{xy}$
and distance along the beamline, $d_z$.

\subsection{Muons} \label{sec:muon-def}

An isolated muon gives one of the cleanest signatures in CMS,
with only perhaps the exception of an isolated photon that does not
undergo pair production in the pixel tracker.
Muons can also show up in jets from weakly decaying hadrons,
in which case they are not isolated.
Since weakly decaying $b$ jets are central to this analysis,
events with non-isolated leptons are not rejected,
but the distinction is important.

Pre-selected muons must meet the following requirements.
\begin{itemize}
\item The muon must have a relatively high energy of $p_T > \SI{5}{GeV}$.
\item The muon should be located in the barrel within $|\eta| < 2.4$.
\item The muon originates from the primary vertex, satisfying both
  $d_{xy} < \SI{0.5}{cm}$ and $d_z < \SI{1.0}{cm}$.
\item The muon must pass a loose isolation cut of $I < 0.4$.
\item The muon must be a PF muon.
\item The muon is either a global muon or a tracker muon.
\end{itemize}

Fully selected muons have some additional cuts they must pass.
\begin{itemize}
\item They must have a higher transverse momentum at $p_T > \SI{25}{GeV}$.
  In events with two muons, such as caused by $Z \rightarrow \mu\mu$,
  the second muon can pass the slightly looser cut of $p_T > \SI{15}{GeV}$.
\item The muon must be a global muon, leaving tracks in both the central tracker
  and the muon chambers.
\item There must be more than five hits in the inner tracker with one hit on a pixel.
\item The fit for the global muon track must be good with $\chi^2/ndof < 10$.
\item The muon must be well isolated with $I < 0.06$
\end{itemize}

These definitions are accepted by all members of the CMS collaboration
as loose and tight working points, respectively.
This allows the analysis to use efficiency measurements created for wider use.

\subsection{Electrons} \label{sec:ele-def}

The kinematic variables associated with an electron are extracted from the GSF fit.
Pre-selected electrons must meet the following requirements.
\begin{itemize}
\item They must have a high transverse momentum with $p_T > \SI{7}{GeV}$
\item They should be centered in the detector with $|\eta| < 2.4$.
\item They originate from the primary vertex with
  $d_{xy} < \SI{0.05}{cm}$ and $d_Z < \SI{0.2}{cm}$.
\item They pass a loose isolation cut of $I < 0.4$.
\end{itemize}

To reduce backgrounds, electrons are identified with the aid of an MVA \cite{Rembser_2019}.
Fully selected electrons pass the tight working point used by the CMS collaboration.
In order to also match the samples of simulated electrons used in the training sample,
the selected electrons also must pass the following cuts.
\begin{itemize}
\item The electron must have higher energy with $p_T > \SI{15}{GeV}$.
\item The deposit of HCAL energy must be less than 9\% of the ECAL energy deposit
  along the electron track.
\item The track sum $p_T$ component of the isolation must be
  less than 18\% of the electron $p_T$.
\item The electron must either have $|\eta| < 1.4442$ or $|\eta| > 1.5660$
\item For electrons with $|\eta| < 1.4442$:
  \begin{itemize}
  \item $\sigma_{i\eta i\eta} < 0.012$
  \item Isolation in the ECAL cluster must be less than 0.4,
    and isolation in the HCAL must be less than 0.25.
  \item The difference between super cluster and track location of the electron
    must be small with $\Delta \eta < 0.0095$ and $\Delta \phi < 0.065$.
  \end{itemize}
\item For electrons with $|\eta| > 1.5660$:
  \begin{itemize}
  \item $\sigma_{i\eta i\eta} < 0.033$
  \item Isolation in the ECAL cluster must be less than 0.45,
    and isolation in the HCAL must be less than 0.28.
  \end{itemize}
\end{itemize}
There is a gap in the $\eta$ direction that accounts for a gap in the CMS detector.
This gap in the active detecting volume is needed to
accommodate various electronics and structural components.

\subsection{Jets} \label{sec:jets-def}

As described in Section~\ref{sec:lhc},
hadrons produced at the LHC are often accompanied by sprays of particles called jets.
Conservation of energy and momentum means that the sum of jet constituents
give the kinematics of the initial parton that produced them.
Jets are constructed by clustering all particle-flow candidates
with the anti-$k_T$ algorithm \cite{Cacciari_2008} using $R = 0.4$.
Due to factors like pileup and detector response,
the energy of the reconstructed jets are corrected \cite{Khachatryan_2017}.

Loose jet cuts, based on the constituents,
are applied to remove jets constructed from detector noise.
Jets that get a significant fraction of their energy from pileup are also removed.
Pre-selected electrons and muons are also often reconstructed as jets.
Any jet within $\Delta R < 0.4$ from a pre-selected lepton is removed.

To be considered for the study of decay products of the Higgs boson,
jets must be within the barrel of the detector with $|\eta| < 2.5$.
The jets must satisfy $p_T > \SI{25}{GeV}$ for the zero and one lepton signatures.
The two lepton signature from $Z(\ell\ell)H$ is cleaner and can apply the looser
criteria of $p_T > \SI{20}{GeV}$ to the jets.

\subsection{Identification of $b$ Jets and Energy Regression}

As mentioned in Section~\ref{sec:requirements} while motivating the design of CMS,
jets containing $b$ hadrons have a distinct signature.
This includes secondary vertices displaced from the beamline,
as well as non-isolated leptons from weak decays.
All of these features are considered in a deep neural network (DNN)
called Deep Combined Secondary Vertex (DeepCSV) \cite{Sirunyan_2018}.
The output of DeepCSV has three working points
that are defined based on the amount of false positives that can be expected
in a collection of jets passing the cut.
The specific values are different for each year of operation.
They are given in Table~\ref{tab:deepcsv}.
\begin{table}
  \centering
  \caption[DeepCSV working points]{
    The cuts for each DeepCSV working point are defined for each year of Run~2 of the LHC.
    The working points are defined by their mis-tag rates.
  }
  {\renewcommand{\arraystretch}{1.5}
  \begin{tabular}{|c | c | c c c|}
    \hline
    Working Point & Mistag Rate & 2016 & 2017 & 2018 \\
    \hline
    Loose  &  10\% & 0.2219 & 0.1522 & 0.1241 \\
    Medium &   1\% & 0.6324 & 0.4941 & 0.4184 \\
    Tight  & 0.1\% & 0.8958 & 0.8001 & 0.7527 \\
    \hline
  \end{tabular}
  }
  \label{tab:deepcsv}
\end{table}

The non-isolated leptons within $b$ jets are caused
by flavor-changing weak decay of $b$ hadrons.
This decay mode also results in neutrinos which carry away a portion of the jet energy.
In order to more accurately reconstruct the di-jet mass of a candidate Higgs decay,
a prediction on the amount of energy carried away by undetected neutrinos is made.
A Deep Neural Network (DNN) is trained in Tensorflow
\cite{DBLP:journals/corr/AbadiABBCCCDDDG16},
which is designed to improve the energy measurement and resolution of all $b$ jets for CMS
\cite{collaboration2019deep}.
The following variables are used as inputs to the regression:
\begin{itemize}
\item the jet's $p_T$, $\eta$, mass and transverse mass
\item the event's median energy density, commonly denoted as $\rho$
\item information about the hardest lepton clustered into the jet,
  including momentum perpendicular to the jet,
  distance $\Delta R$ from the center of the jet,
  and the lepton's flavor
\item the $p_T$, mass, and number of tracks from any secondary vertex linked to the jet,
  as well as the secondary vertex's distance from the collision point and
  associated uncertainties
\item the fractions energy in the jet due to
  charged and neutral hadrons and electromagnetic consistuents
\item the highest $p_T$ of charged hadron consituents
\item the energy fraction contained in five concentric rings around the jet center
  binned by $\Delta R \in [0, 0.05, 0.1, 0.2, 0.3, 0.4]$
\item number of PF candidates in a jet
\item energy sharing computed by
  \[
  \frac{\sqrt{\sum_i p_{T,i}^2}}{\sum_i p_{T,i}}}
  \]
  where $i$ runs over the jet constituents
\end{itemize}
This list results in 41 input variables for the DNN.

\subsection{Fat Jets}

A second collection of jets is made from the same set of PF Candidates that are
clustered to create the jets described in Section~\ref{sec:jets-def}.
This collection also uses the anti-$k_T$ algorithm, but with $R = 0.8$.
This results in larger jets, which are labelled fat jets.
The purpose of this collection is to study events where the Higgs is highly boosted
and its decay products are close enough together that they would not be clustered
into two separate jets.
The larger cone size of the fat jet allows the single jets analyzed to contain
all radiation from the decay products.
The requirement on the fat jet to ensure that most Higgs decay products are contained
in the jet is $p_T > \SI{250}{GeV}$.

Being significantly larger,
the fat jets also contain much additional radiation from the underlying event.
As a result, the invariant mass of the constituents collected into the jet
ends up being much larger than the original mass of the primary parent particle
that contributed most to the jet.
A number of grooming algorithms were considered within CMS \cite{dabercro2014}.
The soft drop algorithm \cite{Larkoski_2014} was chosen as the standard in the experiement
and is used in this analysis.
The resulting groomed mass of the jet is close to its original parent particle.
It has the additional benefit of forcing pileup jets to low mass.
Due to this, a second requirement on fat jets considered for the analysis is
$m_\mathrm{SD} > \SI{50}{GeV}$.

\subsection{Missing Transverse Energy}

Missing transverse energy, also labelled $E_T^\mathrm{miss}$ or MET,
is a vector that takes advantage of the fact that momentum
transverse to the beamline is conserved.
MET is calculated by first taking the negative vector sum of the transverse momentum of
all particle flow candidates in the event.
The resulting vector is then adjusted by taking into account the difference
between the uncorrected and corrected jet energies \cite{collaboration_2015}.
The resulting magnitude and direction is a proxy for the transverse momentum of
any neutrinos in the event.
However, large MET values can be generated by instrumental and beam effects as well.
Therefore, there are additional event filters applied to events with large MET
that removes events where the rest of the detector exhibits suspicious behavior.

\subsection{Soft Hadronic Activity}

In signal $VH$ events, hadronic activity outside of the \bb decay of the Higgs is expected to be low.
This hadronic activity is defined by considering the additional charged PF tracks coming from the primary vertex.
An exclusion region is defined in an ellipse in $(\eta, \phi)$ space containing the two selected $b$ jets
with a major axis length of $\Delta R (\bb) + 1$ and a minor axis length of 1.
All charged tracks outside of this ellipse that also do not correspond with the selected leptons and
that satisfy $p_T > \SI{300}{MeV}$ and $d_Z < \SI{0.2}{cm}$ are clustered
using the anti-$k_T$ algorithm \cite{Cacciari_2008} with $R = 0.4$.
The resulting collection of soft jets is used to define four variables:

\begin{itemize}
\item $H_T^\mathrm{soft}$ -- The scalar sum of soft jets' $p_T$ for jets with $p_T > \SI{1}{GeV}$
\item $N_2^\mathrm{soft}$ -- The number of soft jets with $p_T > \SI{2}{GeV}$
\item $N_5^\mathrm{soft}$ -- The number of soft jets with $p_T > \SI{5}{GeV}$
\item $N_{10}^\mathrm{soft}$ -- The number of soft jets with $p_T > \SI{10}{GeV}$
\end{itemize}

These variables are used in the training of the BDT that discriminates signal and background events.

\subsection{Kinematic Fit}

In the two-lepton region, the all of the $Z$ boson's decay products can be observed and
its momentum can be reconstructed precisely.
A kinematic fit is performed to constrain the leptons' momenta additionally by requiring their
invariant mass to match the $Z$ boson mass.
After this constraint is applied, the tranvserve momentum of the dijet system,
along with ISR jets, is balanced with the transverse momentum of the dilepton system.
The fit is performed by minimizing the chi-squared of the kinematic system that meets these constraints.

For electrons and muons, the corrections defined by their respective Physics Objects Groups
in CMS include uncertainties.
The energy uncertainty used for the $b$-jets and recoils jets is the same as that used
by the $HH \rightarrow \bb\bb$ analysis from CMS \cite{Sirunyan_2019}.
The mass of the $Z$ boson is given a Gaussian uncertainty of \SI{5}{GeV},
and it is assumed that the MET in the event is 0.
The kinematic fit minimizes the chi-squared value of these constraints,
resulting in new energies for all particles in the fit.
The full implementation is in the \texttt{PhysicsTools/KinFitter} package of
\texttt{CMSSW\_10\_2\_0\_pre3} \cite{cmssw_doxygen}.
Only the resulting energies of the $b$-jets, which are otherwise relatively loosely constrained,
are used for analyzing the two-lepton regions.
The improvement of the di-jet mass in the signal sample as a result of the kinematic fit
can be seen in Figure~\ref{fig:kinfit} and Table~\ref{tab:kinfit}.

\begin{figure}
  \includegraphics[width=\linewidth]{figures/fits_SR_medhigh_Hmass__.pdf}
  \caption[Higgs di-jet mass fit with kinematic fit]{
    The Higgs di-jet mass in the 2-lepton signal samples is shown above.
    Peaks from the raw jet, the regressed jet energy, and the kinematic fit are compared.
  }
  \label{fig:kinfit}
\end{figure}

\begin{table}
  \centering
  \caption[Mass resolutions after kinematic fit]{
    The value of $\sigma/\mu$ for each fitted di-jet mass peak is shown below.
    Figure~\ref{fig:kinfit} shows the mass peaks that were fit to fill the inclusive column.
  }
  \begin{tabular}{|r|c|c|c|}
    \hline
    & Low $p_T$ & High $p_T$ & incl. \\
    \hline
    No R. & 0.157 & 0.133 & 0.150 \\
    Reg.  & 0.134 & 0.121 & 0.130 \\
    Fit   & 0.129 & 0.112 & 0.124 \\
    \hline
  \end{tabular}
  \label{tab:kinfit}
\end{table}

\section{Backgrounds to the Analysis}

In order to effectively measure Higgs production,
we need to be able to accurately estimate other events
that end up in our selection.
For example, the final state for the two lepton decay in Figure~\ref{fig:two-lep-diagram}
can also be achieved by a Drell-Yan process radiating jets
or a $t\bar{t}$ event where both $W$ bosons from the top decays decay leptonically.
Feynman diagrams in Figure~\ref{fig:dy-2lep} and Figure~\ref{fig:tt-2lep}
show how the two respective processes can result in
the same final state as the signal process.
The Drell-Yan process can also radiate jets initiated by lighter flavor quarks
that are mistakenly identified as $b$-jets,
and those make up a significant portion of the backgrounds as well.
Less significant, but still important backgrounds include processes like
di-boson production, QCD jets, and signal top processes.

\begin{figure}
  \centering
  \begin{fmffile}{dy_2lep}
    \fmfframe(0,0)(0, 20){
    \begin{fmfgraph*}(250, 150)
      \fmfleft{i0,i1}
      \fmfright{o2,o3,o0,o1}
      \fmf{quark}{i1,v0,v1,i0}
      \fmflabel{$\bar{f}$}{i0}
      \fmflabel{$f$}{i1}
      \fmf{boson, label=$Z$}{v0,v2}
      \fmf{fermion}{o0,v2,o1}
      \fmflabel{$\ell^+$}{o0}
      \fmflabel{$\ell^-$}{o1}
      \fmf{gluon, label=$g$}{v1,v3}
      \fmf{fermion}{o2,v3,o3}
      \fmflabel{$\bar{b}$}{o2}
      \fmflabel{$b$}{o3}
    \end{fmfgraph*}
    }
  \end{fmffile}
  \caption[Feynman diagram for DY + jets background]{
    Above is the Feynman diagram matching the two lepton final state coming from
    Drell-Yan and jets.
  }
  \label{fig:dy-2lep}
\end{figure}

\begin{figure}
  \centering
  \begin{fmffile}{tt_2lep}
    \fmfframe(0,0)(0, 20){
    \begin{fmfgraph*}(250, 150)
      \fmfleft{i0,i1}
      \fmfright{o0,o1,o2,o3,o4,o5}
      \fmf{quark}{i1,v0,i0}
      \fmflabel{$\bar{f}$}{i0}
      \fmflabel{$f$}{i1}
      \fmf{gluon, label=$g$}{v0,v1}
      \fmf{fermion, label=$\bar{t}$}{v2,v1}
      \fmf{fermion, label=$t$}{v1,v3}
      \fmf{fermion}{v2,o0}
      \fmflabel{$\bar{b}$}{o0}
      \fmf{boson, label=$W^-$}{v2,v4}
      \fmf{fermion}{o1,v4,o2}
      \fmflabel{$\bar{\nu}$}{o1}
      \fmflabel{$\ell^-$}{o2}
      \fmf{fermion}{v3,o5}
      \fmflabel{$b$}{o5}
      \fmf{boson, label=$W^+$}{v3,v5}
      \fmf{fermion}{o3,v5,o4}
      \fmflabel{$\ell^+$}{o3}
      \fmflabel{$\nu$}{o4}
    \end{fmfgraph*}
    }
  \end{fmffile}
  \caption[Feynman diagram for $t\bar{t}$ background]{
    Above is the Feynman diagram matching the two lepton final state coming from
    fully leptonic $t\bar{t}$ decay.
    In events with little energy carried away by the neutrinos,
    this can appear to be the same as the two-lepton signal process.
  }
  \label{fig:tt-2lep}
\end{figure}

The backgrounds for the one- and zero-lepton signal decay channels are
caused by similar processes.
For the one-lepton decays of $WH$, the Drell-Yan background in Figure~\ref{fig:dy-2lep}
is replaced with a flavor changing current of $W$ + jets.
The $t\bar{t}$ background would instead be caused by either a hadronic decay of
one of the $W$ bosons in Figure~\ref{fig:tt-2lep}
or by one of the pictured leptons travelling out of the detector without being observed.
For the zero-lepton channel, the Drell Yan process is instead replaced with
$Z \rightarrow \nu\bar{\nu}$.
The $t\bar{t}$ process still needs high MET in order to appear to
contain a hard neutrino presence,
so it is most often caused when a single $W$ decays leptonically with the lepton
falling outside of the detector acceptance.
For both of these channels, di-boson, QCD, and single top backgrounds can also contribute.
This simplifies the methods needed to generate Monte Carlo samples,
since the decay mode of each intermediate particle can be randomly selected for each trial.

To accurately estimate the contribution of each of these backgrounds,
control regions are used.
These are selections that are in similar phase spaces as the signal selection,
but are instead enriched with background events.
By comparing the prediction from Monte Carlo to data,
scaling corrections to the simulation can be made for the phase space.

\section{Simplified Template Cross Section Bins}

The measurement performed in this analysis follows the plan to make a
Simplified Template Cross Section (STXS) measurement \cite{Kato:2687920}.
For this measurement, the vector boson produced as well as the $p_T$ of the vector boson
separates data points into different bins.
The clean signal of the $Z\rightarrow\ell\ell$ decay channel allows for more
bins to be measured for $ZH$ processes.
In addition, the middle $p_T$ bin for $Z$ boson production is split by multiplicity
of additional jets.
There are six bins overall:
\begin{itemize}
\item $WH, 150 < p_{T,V} \le 250$
\item $WH, 250 < p_{T,V}$
\item $ZH, 75 < p_{T,V} \le 150$
\item $ZH, 150 < p_{T,V} \le 250, 0J$
\item $ZH, 150 < p_{T,V} \le 250, \ge 1J$
\item $ZH, 250 < p_{T,V}$
\end{itemize}
All of the selections in the following sections are also divided into the appropriate
set of STXS bins for the generation of datacards and fits.

\section{Resolved Analysis Selection}

With objects defined, the selections differ mostly in counting the number
of charged leptons present in the event.
However, other adjustments are made per channel to optimize the presence of signal events.
Therefore, the first channels described will have the most thorough selection description,
with later channel sections noting many similarities and differences.
For each channel, multiple control region selections are also used in order to more accurately
estimate the approximate contribution of each physics process to the events in each phase space,
and these will be described after each channel's signal region.
A summary of cuts for each region in each channel
is given in Table~\ref{tab:resolved}.
A few channel- or region-specific cuts are left out,
but are described in the appropriate sections.

\begin{table}
  \centering
  \caption[Summary of resolved selection cuts]{
    Below is a summary of common cuts for all regions in the resolved channels.
    See the text for each channel for an explanation of variables.
    All energy equivalent values are in GeV.
  }
  \begin{tabular}{|l|c|c|c|c|c|c|c|c|}
    \hline
    \multicolumn{9}{|l|}{0-lepton channel} \\
    \hline
    Region & $p_{T,V}$ & $p_{T,j}$ & max $b$ & min $b$ & $p_{T,jj}$ & $m_{jj}$ & $N_\textrm{aj}$ & $\Delta\phi(jj, V)$ \\
    \hline
    Signal & 170 & 60, 35 & med. & loose & 120 & >90, <150 & $\le 1$ & $> 2.0$ \\
    Z + $b$ & 170 & 60, 35 & med. & loose & 120 & <90 or >150 & $\le 1$ & $> 2.0$ \\
    Z + $udsg$ & 170 & 60, 35 & !med. & loose & 120 & >50, <500 & $\le 1$ & $> 2.0$ \\
    $t\bar{t}$ & 170 & 60, 35 & med. & loose & 120 & >50, <500 & $\ge 2$ & -- \\
    \hline
    \hline
    \multicolumn{9}{|l|}{1-lepton channel} \\
    \hline
    Region & $p_{T,V}$ & $p_{T,j}$ & max $b$ & min $b$ & $p_{T,jj}$ & $m_{jj}$ & $N_\textrm{aj}$ & $\Delta\phi(jj, V)$ \\
    \hline
    Signal & 150 & 25 & med. & loose & 100 & >90, <150 & $\le 1$ & $> 2.5$ \\
    W + $b$ & 150 & 25 & med. & loose & 100 & <90 or >150 & $\le 1$ & $> 2.5$ \\
    W + $udsg$ & 150 & 25 & !med. & loose & 100 & >50, <250 & -- & $> 2.5$ \\
    $t\bar{t}$ & 150 & 25 & med. & loose & 100 & >50, <250 & $\ge 2$ & -- \\
    \hline
    \hline
    \multicolumn{9}{|l|}{2-lepton channel} \\
    \hline
    Region & $p_{T,V}$ & $p_{T,j}$ & max $b$ & min $b$ & $p_{T,jj}$ & $m_{jj}$ & $N_\textrm{aj}$ & $\Delta\phi(jj, V)$ \\
    \hline
    Signal & 50 & 20 & med. & loose & 50 & >90, <150 & -- & $> 2.5$ \\
    Z + $b$ & 50 & 20 & med. & loose & 50 & <90 or >150 & -- & $> 2.5$ \\
    Z + $udsg$ & 50 & 20 & !loose & !loose & 50 & >50, <250 & -- & $> 2.5$ \\
    $t\bar{t}$ & 50 & 20 & tight & loose & 50 & >50, <250 & -- & -- \\
    \hline
  \end{tabular}
  \label{tab:resolved}
\end{table}

\subsection{0 Leptons} \label{sec:resolved-0}

In the 0-lepton channel, the transverse momentum carried away by the neutrinos
in the $Z$ boson decay results in a large amount of MET.
Therefore, the MET for the event must be larger than \SI{170}{GeV}.
During the 2018 run, a number of HCAL endcap modules were taken offline
due to power supply problems.
These modules were all located in the region $-1.57 < \phi < -0.87$,
so an excess number of high MET events with $\phi_\mathrm{MET}$ in that region were recorded
in later 2018 runs when jets would have been registered in the deactivated detector elements.
The resulting peak can be seen in Figure~\ref{fig:met-peak}.
To handle this, all events with $-1.86 < \phi_\mathrm{MET} < -0.7$ that occurred
during and after run 319077, when the faulty detector elements were shut off.
\begin{figure}
  \centering
  \includegraphics[width=0.8\linewidth]{figures/METPhi319077.pdf}
  \caption[MET $\phi$ distribution before and after shutting off HCAL modules]{
    Above compares the MET $\phi$ distributions before and after shutting off
    problematic HCAL modules during for run 319077.
    The excess of events in the region $-1.86 < \phi_\mathrm{MET} < -0.7$
    is caused by mis-measuring the momenta of forward jets in that region.
  }
  \label{fig:met-peak}
\end{figure}

In addition to the neutrino decay of the $Z$ boson,
the \bb decay of the Higgs also needs to be selected and backgrounds need to be removed.
Many of the following cuts are similar for all of the channels.
For the Higgs decay, Two jets are selected:
the jet with the highest $b$-tag score with $p_T > \SI{60}{GeV}$,
and the jet with the highest or second highest (if the first jet is the highest)
$b$-tag score with $p_T > \SI{35}{GeV}$.
Both of these $p_T$ values are evaluated after applying the $b$-jet energy regression.
The di-jet mass is required to be less than \SI{500}{GeV} and to satisfy $p_T > \SI{120}{GeV}$.
Also the di-jet system is selected to be back-to-back with the MET
by requiring $\Delta\phi(\mathrm{MET}, jj) > 2.0$.
To reduce additional backgrounds, events are not considered if there are any isolated leptons
with $|\eta| < 2.5$ and $p_T > \SI{15}{GeV}$.
Finally, to reduce QCD background contributions, all jets in the event with $p_T > \SI{30}{GeV}$
must be a minimum distance from the event MET satisfying $\Delta \phi(\mathrm{MET}, j) > 0.5$.


The signal region is additionally defined by requiring
the selected $b$-jets to be of high quality,
the di-jet system has a mass close to the Higgs,
and low additional hadronic activity.
At least one of the $b$-jets must pass the medium working point for the appropriate year,
and the other $b$-jet must pass the loose working point.
The value of the di-jet mass must satisfy $\SI{90}{GeV} < m_{jj} < \SI{150}{GeV}$.
At most only one jet with $p_T > \SI{30}{GeV}$ is allows in addition to the selected $b$-jets.
Finally, the PF MET and Track MET must have good agreement with
$\Delta \phi(\mathrm{MET}, \mathrm{trkMET}) < 0.5$.

There are three background processes that are present in the signal selection.
Two processes that need to be treated separately are both when a $Z \rightarrow \nu\bar{\nu}$
occurs recoiling off of jets.
In one processes, the recoiling jets are $b$-jets,
and in the other, the jets are light jets.
Since the fraction of actual $Z \rightarrow \nu\bar{\nu}$ events
containing $b$-jets is not well known, we want to scale them separately.
The third background process that needs to be separately measured in this phase space
is a $t\bar{t}$ semi-leptonic decay where the lepton falls outside of the detector acceptance.
This type of background would also result in a final state with high MET and $b$-jets.

Of the three processes,
the $Z$ + heavy flavor jets selection is the most similar to the signal selection.
The only difference is the di-jet mass.
Events with a mass between $\SI{50}{GeV} < m_{jj} < \SI{500}{GeV}$ but not between
$\SI{90}{GeV} < m_{jj} < \SI{150}{GeV}$, which is the signal region window,
are selected to quantify the $Z$ + heavy flavor.
The $Z$ + light flavor selection includes the entire mass range,
without a veto for the Higgs mass.
It is instead enriched with light jets by requiring that the selected $b$-jet with
a higher $b$-tag score fails the medium working point.
The selection for $t\bar{t}$ events is different from the signal selection
mostly because more hadronic activity is expected.
It uses the same full di-jet mass window as the $Z$ + light flavor region,
but requires at least two additional jets with $p_T > \SI{30}{GeV}$ instead of zero or one.
Also, the $\Delta \phi(\mathrm{MET}, \mathrm{trkMET})$ requirement is dropped.

\subsection{1 Lepton} \label{sec:resolved-1}

In the 1-lepton channel, a single fully-selected isolated lepton as defined in
Section~\ref{sec:muon-def} or Section~\ref{sec:ele-def} is required.
That lepton must point in a similar direction of the MET,
satisfying $\Delta \phi(\ell, \mathrm{MET}) < 2.0$.
The $p_T$ of the reconstructed $W$ boson, consisting of the vector sum of MET and the lepton,
must satisfy $p_T > \SI{150}{GeV}$.
If there are any additional leptons, the event is not used.
The presence of an isolated lepton provides
a much cleaner signal than in the zero lepton channel.
Therefore, the kinematic cuts on the selected $b$-jets can be looser.
The $b$-jets only need to satisfy $p_T > \SI{25}{GeV}$,
and the di-jet system only needs $p_T > \SI{100}{GeV}$.
Any events with $m_{jj} \ge \SI{250}{GeV}$ are not considered for any regions.
The $b$-tagging requirement is the same as the 0-lepton channel.
There is a slightly tighter cut on the di-jet direction of $\Delta\phi(\mathrm{MET}, jj) > 2.5$.

In the signal region, the additional cuts are again similar to the 0-lepton channel.
The di-jet mass window is the same, as is the requirement of at most one additional jet.
The only other difference aside from the adjusted common cuts listed above
is a lack of dependence on the Track MET.
The change to create the $W$ + heavy flavor jets control region is the exact same as the
$Z$ + heavy flavor region in the 0-lepton channel.
The mass window for the Higgs is vetoed.
The cut for the $W$ + light flavor control region is also the same in terms of $b$-tagging,
but the additional jet requirement is also removed.
The $t\bar{t}$ control region is also the same in that the only changes from the signal region
are a relaxed mass window, the requirement of at least two additional jets,
and no requirement on the di-jet direction relative to MET.

\subsection{2 Leptons} \label{sec:resolved-2}

For the 2-lepton channel, two oppositely charged leptons with the same flavor are required.
They must have an invariant mass satisfying $\SI{75}{GeV} < m_{\ell\ell} < \SI{105}{GeV}$.
This process is clean enough to relax the kinematic cuts on the selected $b$-jets
even further than the relaxed cuts of the 1-lepton channel.
The selected $b$-jets only need to have a regressed $p_T > \SI{20}{GeV}$,
and the di-jet system only needs $p_T > \SI{50}{GeV}$.
There are no cuts on the number of additional, outside of categorization for STXS bins.
The di-jet system still needs to satisfy the tighter cut of $\Delta\phi(jj,V) > 2.5$.

The signal region uses the same $b$-tag and mass window cuts as the other two channels.
For the $Z$ + heavy flavor control region,
the di-lepton mass cut is narrowed to $\SI{85}{GeV} < m_{\ell\ell} < \SI{97}{GeV}$
in order to cut out $t\bar{t}$, and the usual Higgs mass veto is applied.
The MET is also required to be low with $\mathrm{MET} < \SI{60}{GeV}$
for the $Z$ + heavy region, but no other.
For the $Z$ + light flavor region, purity is achieved by making the $b$ tagging requirement
that both selected jets fail the loose working point.
The $t\bar{t}$ region is then selected by requiring
one selected jet to pass the tight working point.
The di-lepton mass value also must be either $\SI{10}{GeV} < m_{\ell\ell} < \SI{75}{GeV}$
or $m_{\ell\ell} > \SI{120}{GeV}$.

\section{Boosted Analysis Selection}

When the Higgs has very high $p_T$,
the jet clustering algorithms can find both daughter particles
as being part of a single jet.
The boosted analysis only targets the STXS bins with $p_{T,V} > \SI{250}{GeV}$.
The selection differs primarily in the fact that a single fat jet
which passes a double $b$-tag cut \cite{Sirunyan_2018}
is used to reconstruct the potential Higgs instead of two $b$-tagged jets.
The double $b$-tagger used in this analysis is DeepAK8,
a DNN as opposed to a BDT tagger.
The output is decorrelated with mass, allowing for the jet mass to be used
to generate control regions, as is done in the resolved analysis.

Additional $b$ jets outside of the fat jet are also counted to define selections.
These come from the regular jet collections of Section~\ref{sec:jets-def}.
In order to count as an additional $b$-jet,
the jet must pass the DeepCSV medium working point,
have a regressed $p_T > \SI{25}{GeV}$, and be outside of the selected fat jet
so that $\Delta R(j, fj) > 0.8$.

\subsection{0 Leptons}

As in Section~\ref{sec:resolved-0}, the lack of measured leptons is caused by
the $Z$ boson decaying to neutrinos, so the 0-lepton channel has high MET.
A requirement of $\mathrm{MET} > \SI{250}{GeV}$ is applied,
balancing out the $p_T$ requirement of the fat jet.
As for the resolved analysis, any extra leptons leads to the event not being considered
for the 0-lepton channel.
To remove QCD background for all regions, the same cut from the resolved analysis of
$\Delta \phi(\mathrm{MET}, j) > 0.5$ for all jets with $p_T > \SI{30}{GeV}$ is used.

In the signal region, jets must have a score of 0.8 or higher in the
bbVsLight output node of the DeepAK8 tagger.
They must also have a soft drop mass in the range of $90 < m_\mathrm{SD} < \SI{150}{GeV}$.
No additional jets outside of the fatjet are allowed in the event.
The control regions are the same as for the resovled analysis:
$Z$ + heavy flavor, $Z$ + light flavor, and $t\bar{t}$.
For the $Z$ + heavy flavor control region,
the mass cut is changed to instead veto the Higgs mass window.
For the $Z$ + light flavor, there is no mass requirement outside of the
$m_\textrm{SD} > \SI{50}{GeV}$ required for all fat jets.
Orthogonality is enforced by requiring the bbVsLight score to be less than 0.8.
For $t\bar{t}$, the lack of mass requirement is also present,
but there must be at least one $b$ jet outside of the fat jet.

\subsection{1 Lepton}

For the single lepton channel, exactly one selected lepton must be present.
It must also point in the same direction as the MET with $\Delta \phi(MET, \ell) < 2.0$.
Otherwise, the selection criteria for the different 1-lepton regions
are the exact same as for the boosted 0-lepton regions.

\subsection{2 Leptons}

For the two lepton channel, two oppositely charged, same flavor leptons must be present,
as described in Section~\ref{sec:resolved-2}.
These leptons must also have an invariant mass near the $Z$ boson mass for the signal region
and the two $Z$ + jets regions.
The selection for the signal and control regions are otherwise similar to the selections
for the 0- and 1-lepton channels in the boosted analysis.
The only difference is that instead of requiring a $b$ jet outside of the fat jet
for the $t\bar{t}$ control region,
a mass veto of the di-lepton mass is applied, just as was done for the resolved analysis.

\section{Overlap in Resolved and Boosted Selections}

An important note is that each signal and control region described in this section and the next
is orthogonal to all other regions.
To prevent any statistical bias in the analysis,
both simulated and measured events must not be double counted.
This is most relevant when comparing the resolved and boosted channels since
the same PF Candidates are reused to define two different kinds of jet collections,
making it harder to enforce orthogonality with a single cut.
The overlapping events were given priority to boosted or resolved depending on
a study done to optimize each STXS bin.
Any events that are in both selections are assigned to the resolved analysis,
unless the event is in a resolved control region and a boosted signal region.
